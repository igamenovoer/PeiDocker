# GPU-enabled container with Miniconda baked into the image
# This example creates a GPU-capable container with Miniconda pre-installed during build
# All software and data is stored within the image (no external volumes)

stage_1:
  # Base image configuration - using NVIDIA CUDA runtime
  image:
    base: nvidia/cuda:12.3.2-runtime-ubuntu22.04  # CUDA 12.3.2 runtime on Ubuntu 22.04
    output: pei-image:stage-1                      # Name of the generated stage-1 image
  
  # SSH server configuration
  ssh:
    enable: true                    # Enable SSH server in the container
    port: 22                       # SSH port inside the container
    host_port: 2222                # Port on host machine mapped to container SSH port
    
    # Define SSH users with their passwords
    users:
      me:
        password: '123456'          # Regular user for development
      root:
        password: root              # Root user for admin tasks
  
  # Package repository configuration for faster downloads
  apt:
    repo_source: tuna              # Use Tsinghua University mirror (good for China/Asia)
  
  # GPU support configuration
  device:
    type: gpu                      # Enable GPU support (requires NVIDIA Docker runtime)
  
  # GPU-specific environment variables
  environment:
    - CUDA_VISIBLE_DEVICES=0       # Make first GPU visible to container
    - NVIDIA_DRIVER_CAPABILITIES=all  # Enable all NVIDIA driver capabilities

# Stage 2: Application layer with in-image storage and pre-installed Miniconda
stage_2:
  # Image configuration
  image:
    output: pei-image:stage-2      # Name of the final stage-2 image
  
  # GPU support (inherited from stage-1 but can be overridden)
  device:
    type: gpu                      # Maintain GPU support in final image
  
  # In-image storage configuration (everything stored within the image)
  storage:
    app:                           # Directory for installed applications (including Miniconda)
      type: image                  # Store directly in the Docker image
    data:                          # Directory for data files
      type: image                  # Store directly in the Docker image
    workspace:                     # Directory for workspace/code
      type: image                  # Store directly in the Docker image
  
  # Custom scripts configuration
  custom:
    on_build:                      # Scripts to run during image building
    - stage-2/system/conda/auto-install-miniconda.sh  # Install Miniconda during build

# Note: Miniconda is installed during image build, not at runtime
# This creates a larger image but faster container startup
# Storage directories are accessible as:
# /soft/app -> /hard/image/app (baked into image)
# /soft/data -> /hard/image/data (baked into image)
# /soft/workspace -> /hard/image/workspace (baked into image)
# Data will be lost when container is removed unless committed to new image
